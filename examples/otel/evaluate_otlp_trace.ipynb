{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Grounded AI - OpenTelemetry Trace Evaluation Example\n",
                "\n",
                "This notebook demonstrates how to convert OpenTelemetry GenAI traces into Grounded AI conversations.\n",
                "It evaluates both standard chat responses and complex tool usage scenarios."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# %pip install grounded-ai"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "from pydantic import BaseModel, Field\n",
                "from grounded_ai import Evaluator\n",
                "from grounded_ai.otel import TraceConverter\n",
                "\n",
                "# Check for API Key\n",
                "if \"OPENAI_API_KEY\" not in os.environ:\n",
                "    print(\"⚠️ Please set OPENAI_API_KEY environment variable to run evaluations.\")\n",
                "    # os.environ[\"OPENAI_API_KEY\"] = \"sk-...\""
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Define Standard Chat Span\n",
                "A simple conversation: System -> User -> Assistant."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "chat_span = {\n",
                "    \"trace_id\": \"a1b2c3d4e5f6a1b2c3d4e5f6a1b2c3d4\",\n",
                "    \"span_id\": \"1a2b3c4d1a2b3c4d\",\n",
                "    \"name\": \"chat gpt-4o-mini\",\n",
                "    \"start_time\": \"2026-01-15T10:30:00Z\",\n",
                "    \"end_time\": \"2026-01-15T10:30:02Z\",\n",
                "    \"attributes\": {\n",
                "        \"gen_ai.system\": \"openai\",\n",
                "        \"gen_ai.request.model\": \"gpt-4o-mini\",\n",
                "        \"gen_ai.usage.input_tokens\": 12,\n",
                "        \"gen_ai.usage.output_tokens\": 16,\n",
                "        \"gen_ai.input.messages\": [\n",
                "            {\n",
                "                \"role\": \"system\",\n",
                "                \"parts\": [{\"type\": \"text\", \"content\": \"You are a helpful assistant.\"}]\n",
                "            },\n",
                "            {\n",
                "                \"role\": \"user\",\n",
                "                \"parts\": [{\"type\": \"text\", \"content\": \"What is the capital of France?\"}]\n",
                "            }\n",
                "        ],\n",
                "        \"gen_ai.output.messages\": [\n",
                "            {\n",
                "                \"role\": \"assistant\",\n",
                "                \"parts\": [{\"type\": \"text\", \"content\": \"The capital of France is Berlin.\"}]\n",
                "            }\n",
                "        ]\n",
                "    }\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Define Tool Usage Span\n",
                "A multi-turn interaction embedded in one span: User -> Assistant (Call) -> Tool (Result) -> Assistant (Final)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "tool_span = {\n",
                "    \"trace_id\": \"b2c3d4e5f6a1b2c3d4e5f6a1b2c3d4e5\",\n",
                "    \"span_id\": \"2b3c4d5e2b3c4d5e\",\n",
                "    \"name\": \"chat gpt-4\",\n",
                "    \"start_time\": \"2026-01-15T10:35:00Z\",\n",
                "    \"end_time\": \"2026-01-15T10:35:05Z\",\n",
                "    \"attributes\": {\n",
                "        \"gen_ai.system\": \"openai\",\n",
                "        \"gen_ai.provider.name\": \"openai\",\n",
                "        \"gen_ai.request.model\": \"gpt-4\",\n",
                "        \"gen_ai.request.max_tokens\": 200,\n",
                "        \"gen_ai.request.top_p\": 1.0,\n",
                "        \"gen_ai.response.id\": \"chatcmpl-call_VSPygqKTWdrhaFErNvMV18Yl\",\n",
                "        \"gen_ai.response.model\": \"gpt-4-0613\",\n",
                "        \"gen_ai.usage.output_tokens\": 52,\n",
                "        \"gen_ai.usage.input_tokens\": 97,\n",
                "        \"gen_ai.response.finish_reasons\": [\"stop\"],\n",
                "        \"gen_ai.input.messages\": [\n",
                "            {\n",
                "                \"role\": \"user\",\n",
                "                \"parts\": [{\"type\": \"text\", \"content\": \"Weather in Paris?\"}]\n",
                "            },\n",
                "            {\n",
                "                \"role\": \"assistant\",\n",
                "                \"parts\": [\n",
                "                    {\n",
                "                        \"type\": \"tool_call\",\n",
                "                        \"id\": \"call_VSPygqKTWdrhaFErNvMV18Yl\",\n",
                "                        \"name\": \"get_weather\",\n",
                "                        \"arguments\": {\"location\": \"Paris\"}\n",
                "                    }\n",
                "                ]\n",
                "            },\n",
                "            {\n",
                "                \"role\": \"tool\",\n",
                "                \"parts\": [\n",
                "                    {\n",
                "                        \"type\": \"tool_call_response\",\n",
                "                        \"id\": \" call_VSPygqKTWdrhaFErNvMV18Yl\",\n",
                "                        \"response\": \"rainy, 57\\u00b0F\"\n",
                "                    }\n",
                "                ]\n",
                "            }\n",
                "        ],\n",
                "        \"gen_ai.output.messages\": [\n",
                "            {\n",
                "                \"role\": \"assistant\",\n",
                "                \"parts\": [\n",
                "                    {\n",
                "                        \"type\": \"text\",\n",
                "                        \"content\": \"The weather in Paris is currently rainy with a temperature of 57\\u00b0F.\"\n",
                "                    }\n",
                "                ],\n",
                "                \"finish_reason\": \"stop\"\n",
                "            }\n",
                "        ]\n",
                "    }\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Convert Traces\n",
                "Use `TraceConverter` to parse the OTLP/JSON spans into Grounded AI conversations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "chat_conversation = TraceConverter.from_otlp([chat_span])\n",
                "tool_conversation = TraceConverter.from_otlp([tool_span])\n",
                "\n",
                "# Print logical representation\n",
                "print(\"--- Chat Conversation ---\")\n",
                "print(chat_conversation.to_evaluation_string())\n",
                "\n",
                "print(\"\\n--- Tool Conversation ---\")\n",
                "print(tool_conversation.to_evaluation_string())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Evaluate\n",
                "Define a metric and run the evaluator on the parsed conversations."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class ResponseCorrectness(BaseModel):\n",
                "    is_correct: bool = Field(\n",
                "        description=\"True if the response accurately answers the user's question.\"\n",
                "    )\n",
                "    explanation: str = Field(description=\"Reasoning for the score.\")\n",
                "\n",
                "evaluator = Evaluator(\n",
                "    model=\"openai/gpt-4o\",\n",
                "    system_prompt=\"You are an expert judge. Evaluate the accuracy of the assistant's response.\",\n",
                ")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2eb91f26",
            "metadata": {},
            "outputs": [],
            "source": [
                "print(\"Evaluating Chat...\")\n",
                "chat_result = evaluator.evaluate(\n",
                "    response=chat_conversation.to_evaluation_string(),\n",
                "    output_schema=ResponseCorrectness\n",
                ")\n",
                "print(f\"Chat Result: {chat_result}\\n\")\n",
                "\n",
                "print(\"Evaluating Tool Usage...\")\n",
                "tool_result = evaluator.evaluate(\n",
                "    response=tool_conversation.to_evaluation_string(),\n",
                "    output_schema=ResponseCorrectness\n",
                ")\n",
                "print(f\"Tool Result: {tool_result}\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.12.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
